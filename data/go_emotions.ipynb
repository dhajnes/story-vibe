{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA for Google Research GoEmotions dataset\n",
    "```\n",
    "conda install datasets\n",
    "```\n",
    "\n",
    "Labels:  \n",
    "  '0': admiration  \n",
    "  '1': amusement  \n",
    "  '2': anger  \n",
    "  '3': annoyance  \n",
    "  '4': approval  \n",
    "  '5': caring  \n",
    "  '6': confusion  \n",
    "  '7': curiosity  \n",
    "  '8': desire  \n",
    "  '9': disappointment  \n",
    "  '10': disapproval  \n",
    "  '11': disgust  \n",
    "  '12': embarrassment  \n",
    "  '13': excitement  \n",
    "  '14': fear  \n",
    "  '15': gratitude  \n",
    "  '16': grief  \n",
    "  '17': joy  \n",
    "  '18': love  \n",
    "  '19': nervousness  \n",
    "  '20': optimism  \n",
    "  '21': pride  \n",
    "  '22': realization  \n",
    "  '23': relief  \n",
    "  '24': remorse  \n",
    "  '25': sadness  \n",
    "  '26': surprise  \n",
    "  '27': neutral     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"google-research-datasets/go_emotions\", \"simplified\")\n",
    "raw_dataset = load_dataset(\"google-research-datasets/go_emotions\", \"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"dataset: {dataset}\")\n",
    "print(\"Column names: \", dataset['train'].column_names)\n",
    "print(\"First dataset entry: \", dataset['train'][0])\n",
    "labels = dataset['train'].features['labels'].feature.names\n",
    "print(f\"labels: {labels}\")\n",
    "# label_columns = [col for col in features if features[col].dtype == 'bool']\n",
    "# print(f\"Label columns: {label_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into pandas dataframe for usual workflow\n",
    "train_df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distribution of labels in the dataset\n",
    "value_counts = train_df[\"labels\"].value_counts()\n",
    "relative_value_counts = train_df[\"labels\"].value_counts(normalize=True)\n",
    "print(labels)\n",
    "# transform from numbers to string labels\n",
    "renamed_value_counts = {}\n",
    "for key, val in value_counts.items():\n",
    "    if len(key) > 1:\n",
    "        continue\n",
    "    renamed_value_counts[labels[key[0]]] = val\n",
    "\n",
    "# plot the label distribution\n",
    "plt.figure(figsize=(10, 3))\n",
    "ax = sns.barplot(x=list(renamed_value_counts.keys()), y=list(renamed_value_counts.values()))\n",
    "ax.set_xticklabels(list(renamed_value_counts.keys()),\n",
    "                   rotation=45,\n",
    "                   fontsize=12,\n",
    "                   ha=\"right\")\n",
    "plt.title(\"Label distribution\", fontsize=16)\n",
    "plt.ylabel(\"# of comments\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'neutral'` sample is very frequent, plot also without the most frequent label to see the rest of the distribution more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the label distribution\n",
    "incomplete_value_counts = copy.deepcopy(renamed_value_counts)\n",
    "del incomplete_value_counts['neutral']\n",
    "plt.figure(figsize=(10, 3))\n",
    "ax = sns.barplot(x=list(incomplete_value_counts.keys()), y=list(incomplete_value_counts.values()))\n",
    "ax.set_xticklabels(list(incomplete_value_counts.keys()),\n",
    "                   rotation=45,\n",
    "                   fontsize=12,\n",
    "                   ha=\"right\")\n",
    "plt.title(\"Label distribution (sans `neutral`)\", fontsize=16)\n",
    "plt.ylabel(\"# of comments\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the length disribution of given training examples in this dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()\n",
    "lengths = train_df['text'].apply(lambda x: len(x))\n",
    "lengths.mean()\n",
    "lengths.std()\n",
    "print(f\"Average dataset sentence length: {lengths.mean():.2f} +- {lengths.std():.2f}\")\n",
    "\n",
    "plt.hist(lengths, bins=100, label=\"GoEmotions dataset\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Input length [symbols]\")\n",
    "plt.ylabel(\"# of entries\")\n",
    "plt.xlim([0,250])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Co-occurrence analysis\n",
    "This cooccurrence map only evaluates the multi-labeled parts of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "stripped_labels = train_df['labels'].apply(lambda x: x if len(x) > 1 else None)\n",
    "stripped_labels = stripped_labels.dropna()\n",
    "\n",
    "co_occurrence_matrix = np.zeros((len(labels), len(labels)))\n",
    "for label_instances in stripped_labels:\n",
    "    for (label1, label2) in combinations(label_instances, 2):\n",
    "        co_occurrence_matrix[label1, label2] += 1\n",
    "        co_occurrence_matrix[label2, label1] += 1\n",
    "        \n",
    "co_occurrence_df = pd.DataFrame(co_occurrence_matrix, index=labels, columns=labels)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(co_occurrence_df, cmap=\"YlGnBu\")\n",
    "plt.title(\"Label Co-occurrence Matrix\")\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top words per sentiment in a wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# get the indices of the single number labels\n",
    "single_labels = train_df['labels'].apply(lambda x: x if len(x) <= 1 else None)\n",
    "single_labels = single_labels.dropna()  #  leave out the multilabeled ones\n",
    "\n",
    "# extract the singlelabeled data by index via iloc\n",
    "single_df = train_df.iloc[single_labels.index]  \n",
    "\n",
    "# transform the singlelabeled data labels from list (e.g. [8]) into int (e.g. 8)\n",
    "single_df['labels'] = single_df['labels'].apply(lambda x: x[0])\n",
    "# print(single_df[single_df['labels'] == 5])\n",
    "\n",
    "\n",
    "custom_stopwords = set(STOPWORDS)\n",
    "# there is lots of anonymization of usernames in the data\n",
    "# \n",
    "custom_stopwords.add(\"NAME\")  \n",
    "\n",
    "for label in range(len(labels)):\n",
    "    \n",
    "    # print(f\"\\n| LABEL : {labels[label]} |\\n\")\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    text = single_df[single_df['labels']==label].text\n",
    "    cloud = WordCloud(\n",
    "        stopwords=custom_stopwords, background_color=\"black\", collocations=False,\n",
    "        width=500, height=300).generate(\" \".join(text))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"{labels[label]}\")\n",
    "    plt.imshow(cloud)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "story-vibe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
