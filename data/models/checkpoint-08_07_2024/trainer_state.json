{
  "best_metric": 0.8166467547416687,
  "best_model_checkpoint": "output/checkpoint-4539",
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 90780,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11015642211940956,
      "grad_norm": 8.736109733581543,
      "learning_rate": 1.2431427627230669e-05,
      "loss": 1.2195,
      "step": 500
    },
    {
      "epoch": 0.2203128442388191,
      "grad_norm": 10.120967864990234,
      "learning_rate": 1.2362579863406038e-05,
      "loss": 0.9763,
      "step": 1000
    },
    {
      "epoch": 0.3304692663582287,
      "grad_norm": 8.792085647583008,
      "learning_rate": 1.2293869795109056e-05,
      "loss": 0.9401,
      "step": 1500
    },
    {
      "epoch": 0.4406256884776382,
      "grad_norm": 10.583372116088867,
      "learning_rate": 1.2225022031284424e-05,
      "loss": 0.8998,
      "step": 2000
    },
    {
      "epoch": 0.5507821105970478,
      "grad_norm": 12.29416561126709,
      "learning_rate": 1.2156174267459794e-05,
      "loss": 0.8627,
      "step": 2500
    },
    {
      "epoch": 0.6609385327164574,
      "grad_norm": 10.07336711883545,
      "learning_rate": 1.2087326503635163e-05,
      "loss": 0.8372,
      "step": 3000
    },
    {
      "epoch": 0.771094954835867,
      "grad_norm": 8.253331184387207,
      "learning_rate": 1.2018478739810531e-05,
      "loss": 0.8545,
      "step": 3500
    },
    {
      "epoch": 0.8812513769552764,
      "grad_norm": 9.043113708496094,
      "learning_rate": 1.19496309759859e-05,
      "loss": 0.8443,
      "step": 4000
    },
    {
      "epoch": 0.991407799074686,
      "grad_norm": 24.495649337768555,
      "learning_rate": 1.1880920907688919e-05,
      "loss": 0.8474,
      "step": 4500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.69415127528584,
      "eval_loss": 0.8166467547416687,
      "eval_runtime": 51.5333,
      "eval_samples_per_second": 88.254,
      "eval_steps_per_second": 11.041,
      "step": 4539
    },
    {
      "epoch": 1.1015642211940957,
      "grad_norm": 9.793161392211914,
      "learning_rate": 1.1812073143864288e-05,
      "loss": 0.7044,
      "step": 5000
    },
    {
      "epoch": 1.2117206433135053,
      "grad_norm": 10.628174781799316,
      "learning_rate": 1.1743225380039658e-05,
      "loss": 0.7012,
      "step": 5500
    },
    {
      "epoch": 1.3218770654329148,
      "grad_norm": 14.553288459777832,
      "learning_rate": 1.1674377616215026e-05,
      "loss": 0.69,
      "step": 6000
    },
    {
      "epoch": 1.4320334875523244,
      "grad_norm": 15.01037311553955,
      "learning_rate": 1.1605529852390395e-05,
      "loss": 0.6921,
      "step": 6500
    },
    {
      "epoch": 1.542189909671734,
      "grad_norm": 7.514714241027832,
      "learning_rate": 1.1536682088565765e-05,
      "loss": 0.7054,
      "step": 7000
    },
    {
      "epoch": 1.6523463317911435,
      "grad_norm": 12.432503700256348,
      "learning_rate": 1.1467972020268781e-05,
      "loss": 0.6934,
      "step": 7500
    },
    {
      "epoch": 1.762502753910553,
      "grad_norm": 12.781964302062988,
      "learning_rate": 1.139912425644415e-05,
      "loss": 0.7125,
      "step": 8000
    },
    {
      "epoch": 1.8726591760299627,
      "grad_norm": 11.839820861816406,
      "learning_rate": 1.1330414188147169e-05,
      "loss": 0.7044,
      "step": 8500
    },
    {
      "epoch": 1.9828155981493722,
      "grad_norm": 10.820600509643555,
      "learning_rate": 1.1261566424322538e-05,
      "loss": 0.7106,
      "step": 9000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.6860158311345647,
      "eval_loss": 0.8394476771354675,
      "eval_runtime": 51.5036,
      "eval_samples_per_second": 88.305,
      "eval_steps_per_second": 11.048,
      "step": 9078
    },
    {
      "epoch": 2.092972020268782,
      "grad_norm": 5.659840106964111,
      "learning_rate": 1.1192718660497906e-05,
      "loss": 0.5592,
      "step": 9500
    },
    {
      "epoch": 2.2031284423881914,
      "grad_norm": 9.071528434753418,
      "learning_rate": 1.1123870896673276e-05,
      "loss": 0.5262,
      "step": 10000
    },
    {
      "epoch": 2.313284864507601,
      "grad_norm": 13.653498649597168,
      "learning_rate": 1.1055023132848645e-05,
      "loss": 0.5627,
      "step": 10500
    },
    {
      "epoch": 2.4234412866270105,
      "grad_norm": 17.971651077270508,
      "learning_rate": 1.0986175369024013e-05,
      "loss": 0.5048,
      "step": 11000
    },
    {
      "epoch": 2.53359770874642,
      "grad_norm": 37.12779235839844,
      "learning_rate": 1.0917327605199383e-05,
      "loss": 0.5532,
      "step": 11500
    },
    {
      "epoch": 2.6437541308658297,
      "grad_norm": 17.167583465576172,
      "learning_rate": 1.0848479841374752e-05,
      "loss": 0.5328,
      "step": 12000
    },
    {
      "epoch": 2.7539105529852392,
      "grad_norm": 20.72726058959961,
      "learning_rate": 1.0779632077550122e-05,
      "loss": 0.5321,
      "step": 12500
    },
    {
      "epoch": 2.864066975104649,
      "grad_norm": 16.538829803466797,
      "learning_rate": 1.071078431372549e-05,
      "loss": 0.543,
      "step": 13000
    },
    {
      "epoch": 2.9742233972240584,
      "grad_norm": 19.95563507080078,
      "learning_rate": 1.064193654990086e-05,
      "loss": 0.5339,
      "step": 13500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.6849164467897977,
      "eval_loss": 0.9576432108879089,
      "eval_runtime": 51.5069,
      "eval_samples_per_second": 88.299,
      "eval_steps_per_second": 11.047,
      "step": 13617
    },
    {
      "epoch": 3.084379819343468,
      "grad_norm": 38.46449279785156,
      "learning_rate": 1.0573226481603877e-05,
      "loss": 0.3959,
      "step": 14000
    },
    {
      "epoch": 3.1945362414628775,
      "grad_norm": 38.151493072509766,
      "learning_rate": 1.0504378717779247e-05,
      "loss": 0.3497,
      "step": 14500
    },
    {
      "epoch": 3.304692663582287,
      "grad_norm": 17.577482223510742,
      "learning_rate": 1.0435530953954615e-05,
      "loss": 0.3862,
      "step": 15000
    },
    {
      "epoch": 3.4148490857016967,
      "grad_norm": 25.528945922851562,
      "learning_rate": 1.0366683190129984e-05,
      "loss": 0.3826,
      "step": 15500
    },
    {
      "epoch": 3.525005507821106,
      "grad_norm": 1.0541677474975586,
      "learning_rate": 1.0297973121833002e-05,
      "loss": 0.3913,
      "step": 16000
    },
    {
      "epoch": 3.635161929940516,
      "grad_norm": 8.81918716430664,
      "learning_rate": 1.0229125358008372e-05,
      "loss": 0.357,
      "step": 16500
    },
    {
      "epoch": 3.7453183520599254,
      "grad_norm": 37.322696685791016,
      "learning_rate": 1.0160277594183742e-05,
      "loss": 0.374,
      "step": 17000
    },
    {
      "epoch": 3.855474774179335,
      "grad_norm": 24.47274398803711,
      "learning_rate": 1.009142983035911e-05,
      "loss": 0.3757,
      "step": 17500
    },
    {
      "epoch": 3.965631196298744,
      "grad_norm": 19.08702850341797,
      "learning_rate": 1.0022857457589778e-05,
      "loss": 0.3943,
      "step": 18000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.6682058047493403,
      "eval_loss": 1.4754287004470825,
      "eval_runtime": 51.5471,
      "eval_samples_per_second": 88.23,
      "eval_steps_per_second": 11.038,
      "step": 18156
    },
    {
      "epoch": 4.075787618418154,
      "grad_norm": 23.31123924255371,
      "learning_rate": 9.954147389292796e-06,
      "loss": 0.2743,
      "step": 18500
    },
    {
      "epoch": 4.185944040537564,
      "grad_norm": 0.9321146607398987,
      "learning_rate": 9.885299625468165e-06,
      "loss": 0.2382,
      "step": 19000
    },
    {
      "epoch": 4.296100462656973,
      "grad_norm": 4.368174076080322,
      "learning_rate": 9.816451861643535e-06,
      "loss": 0.2657,
      "step": 19500
    },
    {
      "epoch": 4.406256884776383,
      "grad_norm": 31.076955795288086,
      "learning_rate": 9.747604097818904e-06,
      "loss": 0.2638,
      "step": 20000
    },
    {
      "epoch": 4.516413306895792,
      "grad_norm": 62.35398483276367,
      "learning_rate": 9.678756333994272e-06,
      "loss": 0.2835,
      "step": 20500
    },
    {
      "epoch": 4.626569729015202,
      "grad_norm": 9.623316764831543,
      "learning_rate": 9.609908570169642e-06,
      "loss": 0.2759,
      "step": 21000
    },
    {
      "epoch": 4.7367261511346115,
      "grad_norm": 34.46937561035156,
      "learning_rate": 9.541060806345011e-06,
      "loss": 0.2839,
      "step": 21500
    },
    {
      "epoch": 4.846882573254021,
      "grad_norm": 53.489654541015625,
      "learning_rate": 9.472213042520379e-06,
      "loss": 0.2959,
      "step": 22000
    },
    {
      "epoch": 4.957038995373431,
      "grad_norm": 2.0513508319854736,
      "learning_rate": 9.403365278695749e-06,
      "loss": 0.2789,
      "step": 22500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.667985927880387,
      "eval_loss": 1.929470181465149,
      "eval_runtime": 51.5749,
      "eval_samples_per_second": 88.183,
      "eval_steps_per_second": 11.033,
      "step": 22695
    },
    {
      "epoch": 5.06719541749284,
      "grad_norm": 0.9965474605560303,
      "learning_rate": 9.334655210398767e-06,
      "loss": 0.2105,
      "step": 23000
    },
    {
      "epoch": 5.17735183961225,
      "grad_norm": 2.347411870956421,
      "learning_rate": 9.265807446574136e-06,
      "loss": 0.1776,
      "step": 23500
    },
    {
      "epoch": 5.287508261731659,
      "grad_norm": 17.559545516967773,
      "learning_rate": 9.197097378277154e-06,
      "loss": 0.2046,
      "step": 24000
    },
    {
      "epoch": 5.397664683851069,
      "grad_norm": 1.7179368734359741,
      "learning_rate": 9.128249614452524e-06,
      "loss": 0.1876,
      "step": 24500
    },
    {
      "epoch": 5.5078211059704785,
      "grad_norm": 40.742469787597656,
      "learning_rate": 9.059401850627892e-06,
      "loss": 0.2068,
      "step": 25000
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 116.99018096923828,
      "learning_rate": 8.990554086803261e-06,
      "loss": 0.2161,
      "step": 25500
    },
    {
      "epoch": 5.728133950209298,
      "grad_norm": 25.582395553588867,
      "learning_rate": 8.921706322978631e-06,
      "loss": 0.2091,
      "step": 26000
    },
    {
      "epoch": 5.838290372328707,
      "grad_norm": 0.04598008841276169,
      "learning_rate": 8.852858559153999e-06,
      "loss": 0.1889,
      "step": 26500
    },
    {
      "epoch": 5.948446794448117,
      "grad_norm": 0.15363110601902008,
      "learning_rate": 8.784010795329368e-06,
      "loss": 0.2065,
      "step": 27000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.6657871591908531,
      "eval_loss": 2.23160982131958,
      "eval_runtime": 51.5164,
      "eval_samples_per_second": 88.282,
      "eval_steps_per_second": 11.045,
      "step": 27234
    },
    {
      "epoch": 6.058603216567526,
      "grad_norm": 0.12071532011032104,
      "learning_rate": 8.715163031504738e-06,
      "loss": 0.1465,
      "step": 27500
    },
    {
      "epoch": 6.168759638686936,
      "grad_norm": 0.3640884757041931,
      "learning_rate": 8.646452963207756e-06,
      "loss": 0.1148,
      "step": 28000
    },
    {
      "epoch": 6.2789160608063455,
      "grad_norm": 0.4155229330062866,
      "learning_rate": 8.577742894910774e-06,
      "loss": 0.1371,
      "step": 28500
    },
    {
      "epoch": 6.389072482925755,
      "grad_norm": 131.54823303222656,
      "learning_rate": 8.508895131086143e-06,
      "loss": 0.1549,
      "step": 29000
    },
    {
      "epoch": 6.499228905045165,
      "grad_norm": 8.132413864135742,
      "learning_rate": 8.440047367261513e-06,
      "loss": 0.1742,
      "step": 29500
    },
    {
      "epoch": 6.609385327164574,
      "grad_norm": 0.12854619324207306,
      "learning_rate": 8.371199603436881e-06,
      "loss": 0.1373,
      "step": 30000
    },
    {
      "epoch": 6.719541749283984,
      "grad_norm": 84.42688751220703,
      "learning_rate": 8.30235183961225e-06,
      "loss": 0.1439,
      "step": 30500
    },
    {
      "epoch": 6.829698171403393,
      "grad_norm": 117.49725341796875,
      "learning_rate": 8.233641771315267e-06,
      "loss": 0.1835,
      "step": 31000
    },
    {
      "epoch": 6.939854593522803,
      "grad_norm": 68.08370971679688,
      "learning_rate": 8.164794007490636e-06,
      "loss": 0.1648,
      "step": 31500
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.6651275285839929,
      "eval_loss": 2.5357604026794434,
      "eval_runtime": 51.5209,
      "eval_samples_per_second": 88.275,
      "eval_steps_per_second": 11.044,
      "step": 31773
    },
    {
      "epoch": 7.0500110156422116,
      "grad_norm": 103.24382019042969,
      "learning_rate": 8.095946243666006e-06,
      "loss": 0.122,
      "step": 32000
    },
    {
      "epoch": 7.160167437761621,
      "grad_norm": 3.690918207168579,
      "learning_rate": 8.027098479841374e-06,
      "loss": 0.0931,
      "step": 32500
    },
    {
      "epoch": 7.270323859881031,
      "grad_norm": 0.01286226511001587,
      "learning_rate": 7.958250716016743e-06,
      "loss": 0.0907,
      "step": 33000
    },
    {
      "epoch": 7.38048028200044,
      "grad_norm": 23.806331634521484,
      "learning_rate": 7.889540647719761e-06,
      "loss": 0.0809,
      "step": 33500
    },
    {
      "epoch": 7.49063670411985,
      "grad_norm": 0.02386835403740406,
      "learning_rate": 7.820692883895131e-06,
      "loss": 0.0923,
      "step": 34000
    },
    {
      "epoch": 7.600793126239259,
      "grad_norm": 0.09966854751110077,
      "learning_rate": 7.7518451200705e-06,
      "loss": 0.098,
      "step": 34500
    },
    {
      "epoch": 7.710949548358669,
      "grad_norm": 29.297029495239258,
      "learning_rate": 7.682997356245868e-06,
      "loss": 0.1179,
      "step": 35000
    },
    {
      "epoch": 7.8211059704780785,
      "grad_norm": 0.010244466364383698,
      "learning_rate": 7.614149592421238e-06,
      "loss": 0.1169,
      "step": 35500
    },
    {
      "epoch": 7.931262392597488,
      "grad_norm": 0.4100891351699829,
      "learning_rate": 7.545301828596607e-06,
      "loss": 0.1198,
      "step": 36000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.662269129287599,
      "eval_loss": 2.701303243637085,
      "eval_runtime": 51.4827,
      "eval_samples_per_second": 88.34,
      "eval_steps_per_second": 11.052,
      "step": 36312
    },
    {
      "epoch": 8.041418814716899,
      "grad_norm": 0.01063611637800932,
      "learning_rate": 7.476454064771976e-06,
      "loss": 0.0911,
      "step": 36500
    },
    {
      "epoch": 8.151575236836308,
      "grad_norm": 0.0023399433121085167,
      "learning_rate": 7.407606300947345e-06,
      "loss": 0.0869,
      "step": 37000
    },
    {
      "epoch": 8.261731658955718,
      "grad_norm": 0.004167940001934767,
      "learning_rate": 7.338896232650364e-06,
      "loss": 0.0826,
      "step": 37500
    },
    {
      "epoch": 8.371888081075127,
      "grad_norm": 0.004609014373272657,
      "learning_rate": 7.270186164353382e-06,
      "loss": 0.0624,
      "step": 38000
    },
    {
      "epoch": 8.482044503194537,
      "grad_norm": 0.011185440234839916,
      "learning_rate": 7.201338400528751e-06,
      "loss": 0.0862,
      "step": 38500
    },
    {
      "epoch": 8.592200925313946,
      "grad_norm": 0.013355129398405552,
      "learning_rate": 7.13249063670412e-06,
      "loss": 0.0833,
      "step": 39000
    },
    {
      "epoch": 8.702357347433356,
      "grad_norm": 0.16276347637176514,
      "learning_rate": 7.063642872879489e-06,
      "loss": 0.0845,
      "step": 39500
    },
    {
      "epoch": 8.812513769552766,
      "grad_norm": 0.02542770653963089,
      "learning_rate": 6.994795109054858e-06,
      "loss": 0.0655,
      "step": 40000
    },
    {
      "epoch": 8.922670191672175,
      "grad_norm": 0.001305641490034759,
      "learning_rate": 6.926085040757876e-06,
      "loss": 0.0874,
      "step": 40500
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.6629287598944591,
      "eval_loss": 2.9606056213378906,
      "eval_runtime": 51.4855,
      "eval_samples_per_second": 88.336,
      "eval_steps_per_second": 11.052,
      "step": 40851
    },
    {
      "epoch": 9.032826613791585,
      "grad_norm": 0.7193624973297119,
      "learning_rate": 6.857237276933245e-06,
      "loss": 0.078,
      "step": 41000
    },
    {
      "epoch": 9.142983035910994,
      "grad_norm": 25.625341415405273,
      "learning_rate": 6.788389513108615e-06,
      "loss": 0.0671,
      "step": 41500
    },
    {
      "epoch": 9.253139458030404,
      "grad_norm": 0.038792166858911514,
      "learning_rate": 6.719541749283983e-06,
      "loss": 0.0621,
      "step": 42000
    },
    {
      "epoch": 9.363295880149813,
      "grad_norm": 0.0436277762055397,
      "learning_rate": 6.650693985459352e-06,
      "loss": 0.0649,
      "step": 42500
    },
    {
      "epoch": 9.473452302269223,
      "grad_norm": 133.72369384765625,
      "learning_rate": 6.581983917162371e-06,
      "loss": 0.0712,
      "step": 43000
    },
    {
      "epoch": 9.583608724388633,
      "grad_norm": 0.004817620851099491,
      "learning_rate": 6.51313615333774e-06,
      "loss": 0.0511,
      "step": 43500
    },
    {
      "epoch": 9.693765146508042,
      "grad_norm": 22.54977798461914,
      "learning_rate": 6.444288389513109e-06,
      "loss": 0.073,
      "step": 44000
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 0.004440439864993095,
      "learning_rate": 6.375440625688478e-06,
      "loss": 0.0571,
      "step": 44500
    },
    {
      "epoch": 9.914077990746861,
      "grad_norm": 0.6743137240409851,
      "learning_rate": 6.306592861863847e-06,
      "loss": 0.0731,
      "step": 45000
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.6728232189973615,
      "eval_loss": 3.023878574371338,
      "eval_runtime": 51.5533,
      "eval_samples_per_second": 88.219,
      "eval_steps_per_second": 11.037,
      "step": 45390
    },
    {
      "epoch": 10.02423441286627,
      "grad_norm": 0.001518729142844677,
      "learning_rate": 6.2378827935668655e-06,
      "loss": 0.0654,
      "step": 45500
    },
    {
      "epoch": 10.13439083498568,
      "grad_norm": 0.0010616250801831484,
      "learning_rate": 6.169035029742234e-06,
      "loss": 0.0542,
      "step": 46000
    },
    {
      "epoch": 10.24454725710509,
      "grad_norm": 0.5685665607452393,
      "learning_rate": 6.100187265917604e-06,
      "loss": 0.0493,
      "step": 46500
    },
    {
      "epoch": 10.3547036792245,
      "grad_norm": 0.03895123675465584,
      "learning_rate": 6.0313395020929726e-06,
      "loss": 0.0563,
      "step": 47000
    },
    {
      "epoch": 10.464860101343909,
      "grad_norm": 0.05632155388593674,
      "learning_rate": 5.962491738268341e-06,
      "loss": 0.0561,
      "step": 47500
    },
    {
      "epoch": 10.575016523463319,
      "grad_norm": 0.02276556007564068,
      "learning_rate": 5.893643974443711e-06,
      "loss": 0.0471,
      "step": 48000
    },
    {
      "epoch": 10.685172945582728,
      "grad_norm": 33.60203170776367,
      "learning_rate": 5.824933906146729e-06,
      "loss": 0.065,
      "step": 48500
    },
    {
      "epoch": 10.795329367702138,
      "grad_norm": 0.03445695713162422,
      "learning_rate": 5.756223837849747e-06,
      "loss": 0.0445,
      "step": 49000
    },
    {
      "epoch": 10.905485789821547,
      "grad_norm": 0.026670964434742928,
      "learning_rate": 5.6873760740251156e-06,
      "loss": 0.0467,
      "step": 49500
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.6638082673702727,
      "eval_loss": 3.133244514465332,
      "eval_runtime": 51.4916,
      "eval_samples_per_second": 88.325,
      "eval_steps_per_second": 11.05,
      "step": 49929
    },
    {
      "epoch": 11.015642211940957,
      "grad_norm": 0.0006522146868519485,
      "learning_rate": 5.618528310200485e-06,
      "loss": 0.0522,
      "step": 50000
    },
    {
      "epoch": 11.125798634060367,
      "grad_norm": 0.0012926512863487005,
      "learning_rate": 5.549680546375854e-06,
      "loss": 0.0315,
      "step": 50500
    },
    {
      "epoch": 11.235955056179776,
      "grad_norm": 0.024914585053920746,
      "learning_rate": 5.480832782551223e-06,
      "loss": 0.0479,
      "step": 51000
    },
    {
      "epoch": 11.346111478299186,
      "grad_norm": 1.9154393672943115,
      "learning_rate": 5.411985018726592e-06,
      "loss": 0.0472,
      "step": 51500
    },
    {
      "epoch": 11.456267900418595,
      "grad_norm": 0.007094597909599543,
      "learning_rate": 5.343137254901961e-06,
      "loss": 0.0496,
      "step": 52000
    },
    {
      "epoch": 11.566424322538005,
      "grad_norm": 0.0046602278016507626,
      "learning_rate": 5.274427186604979e-06,
      "loss": 0.0315,
      "step": 52500
    },
    {
      "epoch": 11.676580744657414,
      "grad_norm": 0.0003218589990865439,
      "learning_rate": 5.2055794227803485e-06,
      "loss": 0.0439,
      "step": 53000
    },
    {
      "epoch": 11.786737166776824,
      "grad_norm": 0.014048837125301361,
      "learning_rate": 5.136731658955717e-06,
      "loss": 0.0631,
      "step": 53500
    },
    {
      "epoch": 11.896893588896233,
      "grad_norm": 0.002543424488976598,
      "learning_rate": 5.067883895131086e-06,
      "loss": 0.047,
      "step": 54000
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.6655672823218998,
      "eval_loss": 3.2620389461517334,
      "eval_runtime": 51.4865,
      "eval_samples_per_second": 88.334,
      "eval_steps_per_second": 11.051,
      "step": 54468
    },
    {
      "epoch": 12.007050011015643,
      "grad_norm": 0.10041599720716476,
      "learning_rate": 4.9990361313064555e-06,
      "loss": 0.041,
      "step": 54500
    },
    {
      "epoch": 12.117206433135053,
      "grad_norm": 0.0012186435051262379,
      "learning_rate": 4.930188367481824e-06,
      "loss": 0.0346,
      "step": 55000
    },
    {
      "epoch": 12.227362855254462,
      "grad_norm": 0.00039479308179579675,
      "learning_rate": 4.861340603657193e-06,
      "loss": 0.0376,
      "step": 55500
    },
    {
      "epoch": 12.337519277373872,
      "grad_norm": 25.642650604248047,
      "learning_rate": 4.7924928398325625e-06,
      "loss": 0.031,
      "step": 56000
    },
    {
      "epoch": 12.447675699493281,
      "grad_norm": 0.0006371628842316568,
      "learning_rate": 4.7237827715355805e-06,
      "loss": 0.0321,
      "step": 56500
    },
    {
      "epoch": 12.557832121612691,
      "grad_norm": 0.03482867404818535,
      "learning_rate": 4.65493500771095e-06,
      "loss": 0.0353,
      "step": 57000
    },
    {
      "epoch": 12.6679885437321,
      "grad_norm": 9.841777801513672,
      "learning_rate": 4.586087243886319e-06,
      "loss": 0.04,
      "step": 57500
    },
    {
      "epoch": 12.77814496585151,
      "grad_norm": 21.89223861694336,
      "learning_rate": 4.5172394800616875e-06,
      "loss": 0.0254,
      "step": 58000
    },
    {
      "epoch": 12.88830138797092,
      "grad_norm": 0.0007804214837960899,
      "learning_rate": 4.448391716237057e-06,
      "loss": 0.0295,
      "step": 58500
    },
    {
      "epoch": 12.99845781009033,
      "grad_norm": 0.004889298230409622,
      "learning_rate": 4.379681647940075e-06,
      "loss": 0.0324,
      "step": 59000
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.6688654353562006,
      "eval_loss": 3.226496458053589,
      "eval_runtime": 51.5733,
      "eval_samples_per_second": 88.185,
      "eval_steps_per_second": 11.033,
      "step": 59007
    },
    {
      "epoch": 13.108614232209737,
      "grad_norm": 0.0009767650626599789,
      "learning_rate": 4.310833884115445e-06,
      "loss": 0.0281,
      "step": 59500
    },
    {
      "epoch": 13.218770654329147,
      "grad_norm": 0.0005329495761543512,
      "learning_rate": 4.241986120290813e-06,
      "loss": 0.0216,
      "step": 60000
    },
    {
      "epoch": 13.328927076448556,
      "grad_norm": 2.1761317253112793,
      "learning_rate": 4.173138356466182e-06,
      "loss": 0.0189,
      "step": 60500
    },
    {
      "epoch": 13.439083498567966,
      "grad_norm": 0.0012609169352799654,
      "learning_rate": 4.104428288169201e-06,
      "loss": 0.0319,
      "step": 61000
    },
    {
      "epoch": 13.549239920687375,
      "grad_norm": 0.0004393666749820113,
      "learning_rate": 4.035718219872218e-06,
      "loss": 0.0286,
      "step": 61500
    },
    {
      "epoch": 13.659396342806785,
      "grad_norm": 0.0009089990635402501,
      "learning_rate": 3.966870456047588e-06,
      "loss": 0.0299,
      "step": 62000
    },
    {
      "epoch": 13.769552764926194,
      "grad_norm": 0.0009647951810620725,
      "learning_rate": 3.898022692222956e-06,
      "loss": 0.0194,
      "step": 62500
    },
    {
      "epoch": 13.879709187045604,
      "grad_norm": 0.0018081474117934704,
      "learning_rate": 3.829174928398326e-06,
      "loss": 0.0325,
      "step": 63000
    },
    {
      "epoch": 13.989865609165014,
      "grad_norm": 0.014397034421563148,
      "learning_rate": 3.7603271645736947e-06,
      "loss": 0.0227,
      "step": 63500
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.6721635883905013,
      "eval_loss": 3.3254942893981934,
      "eval_runtime": 51.6014,
      "eval_samples_per_second": 88.137,
      "eval_steps_per_second": 11.027,
      "step": 63546
    },
    {
      "epoch": 14.100022031284423,
      "grad_norm": 0.00536789046600461,
      "learning_rate": 3.6914794007490634e-06,
      "loss": 0.0146,
      "step": 64000
    },
    {
      "epoch": 14.210178453403833,
      "grad_norm": 0.0005047350423410535,
      "learning_rate": 3.6226316369244325e-06,
      "loss": 0.0199,
      "step": 64500
    },
    {
      "epoch": 14.320334875523242,
      "grad_norm": 0.0025625142734497786,
      "learning_rate": 3.5537838730998017e-06,
      "loss": 0.025,
      "step": 65000
    },
    {
      "epoch": 14.430491297642652,
      "grad_norm": 0.001794738695025444,
      "learning_rate": 3.484936109275171e-06,
      "loss": 0.0252,
      "step": 65500
    },
    {
      "epoch": 14.540647719762061,
      "grad_norm": 0.021010447293519974,
      "learning_rate": 3.4162260409781892e-06,
      "loss": 0.0213,
      "step": 66000
    },
    {
      "epoch": 14.650804141881471,
      "grad_norm": 0.002415680792182684,
      "learning_rate": 3.347378277153558e-06,
      "loss": 0.0159,
      "step": 66500
    },
    {
      "epoch": 14.76096056400088,
      "grad_norm": 0.05636072903871536,
      "learning_rate": 3.278530513328927e-06,
      "loss": 0.0356,
      "step": 67000
    },
    {
      "epoch": 14.87111698612029,
      "grad_norm": 0.007750593591481447,
      "learning_rate": 3.2096827495042963e-06,
      "loss": 0.0247,
      "step": 67500
    },
    {
      "epoch": 14.9812734082397,
      "grad_norm": 0.00032692751847207546,
      "learning_rate": 3.1409726812073147e-06,
      "loss": 0.0201,
      "step": 68000
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.6730430958663148,
      "eval_loss": 3.35768723487854,
      "eval_runtime": 51.4657,
      "eval_samples_per_second": 88.369,
      "eval_steps_per_second": 11.056,
      "step": 68085
    },
    {
      "epoch": 15.09142983035911,
      "grad_norm": 0.00064276676857844,
      "learning_rate": 3.0721249173826834e-06,
      "loss": 0.0142,
      "step": 68500
    },
    {
      "epoch": 15.201586252478519,
      "grad_norm": 0.010114883072674274,
      "learning_rate": 3.0032771535580525e-06,
      "loss": 0.0111,
      "step": 69000
    },
    {
      "epoch": 15.311742674597928,
      "grad_norm": 0.0001834857976064086,
      "learning_rate": 2.9344293897334217e-06,
      "loss": 0.023,
      "step": 69500
    },
    {
      "epoch": 15.421899096717338,
      "grad_norm": 0.23721624910831451,
      "learning_rate": 2.86571932143644e-06,
      "loss": 0.0114,
      "step": 70000
    },
    {
      "epoch": 15.532055518836748,
      "grad_norm": 0.0003443051828071475,
      "learning_rate": 2.796871557611809e-06,
      "loss": 0.0163,
      "step": 70500
    },
    {
      "epoch": 15.642211940956157,
      "grad_norm": 0.0009822261054068804,
      "learning_rate": 2.728023793787178e-06,
      "loss": 0.0124,
      "step": 71000
    },
    {
      "epoch": 15.752368363075567,
      "grad_norm": 0.0009357925737276673,
      "learning_rate": 2.659176029962547e-06,
      "loss": 0.018,
      "step": 71500
    },
    {
      "epoch": 15.862524785194976,
      "grad_norm": 0.03943979740142822,
      "learning_rate": 2.5903282661379163e-06,
      "loss": 0.0172,
      "step": 72000
    },
    {
      "epoch": 15.972681207314386,
      "grad_norm": 0.03561825305223465,
      "learning_rate": 2.5216181978409343e-06,
      "loss": 0.0265,
      "step": 72500
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.6765611257695691,
      "eval_loss": 3.431145429611206,
      "eval_runtime": 51.5173,
      "eval_samples_per_second": 88.281,
      "eval_steps_per_second": 11.045,
      "step": 72624
    },
    {
      "epoch": 16.082837629433797,
      "grad_norm": 0.00035574391949921846,
      "learning_rate": 2.452770434016303e-06,
      "loss": 0.0183,
      "step": 73000
    },
    {
      "epoch": 16.192994051553207,
      "grad_norm": 0.0003373526851646602,
      "learning_rate": 2.3840603657193214e-06,
      "loss": 0.0157,
      "step": 73500
    },
    {
      "epoch": 16.303150473672616,
      "grad_norm": 0.0013450710102915764,
      "learning_rate": 2.3152126018946906e-06,
      "loss": 0.0194,
      "step": 74000
    },
    {
      "epoch": 16.413306895792026,
      "grad_norm": 0.0003188379923813045,
      "learning_rate": 2.2463648380700597e-06,
      "loss": 0.0152,
      "step": 74500
    },
    {
      "epoch": 16.523463317911435,
      "grad_norm": 0.0002146010083379224,
      "learning_rate": 2.177517074245429e-06,
      "loss": 0.0163,
      "step": 75000
    },
    {
      "epoch": 16.633619740030845,
      "grad_norm": 0.0003486060304567218,
      "learning_rate": 2.1086693104207976e-06,
      "loss": 0.0115,
      "step": 75500
    },
    {
      "epoch": 16.743776162150255,
      "grad_norm": 0.00043014565017074347,
      "learning_rate": 2.0398215465961667e-06,
      "loss": 0.0193,
      "step": 76000
    },
    {
      "epoch": 16.853932584269664,
      "grad_norm": 0.00025150220608338714,
      "learning_rate": 1.970973782771536e-06,
      "loss": 0.0057,
      "step": 76500
    },
    {
      "epoch": 16.964089006389074,
      "grad_norm": 0.00021117574942763895,
      "learning_rate": 1.9021260189469048e-06,
      "loss": 0.013,
      "step": 77000
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.6772207563764292,
      "eval_loss": 3.4856109619140625,
      "eval_runtime": 51.5128,
      "eval_samples_per_second": 88.289,
      "eval_steps_per_second": 11.046,
      "step": 77163
    },
    {
      "epoch": 17.074245428508483,
      "grad_norm": 0.00013679047697223723,
      "learning_rate": 1.8332782551222737e-06,
      "loss": 0.0124,
      "step": 77500
    },
    {
      "epoch": 17.184401850627893,
      "grad_norm": 0.00020530358597170562,
      "learning_rate": 1.7645681868252922e-06,
      "loss": 0.0128,
      "step": 78000
    },
    {
      "epoch": 17.294558272747302,
      "grad_norm": 0.00048154834075830877,
      "learning_rate": 1.695720423000661e-06,
      "loss": 0.0158,
      "step": 78500
    },
    {
      "epoch": 17.404714694866712,
      "grad_norm": 0.00014406483387574553,
      "learning_rate": 1.6268726591760302e-06,
      "loss": 0.0227,
      "step": 79000
    },
    {
      "epoch": 17.51487111698612,
      "grad_norm": 0.00020843118545599282,
      "learning_rate": 1.558024895351399e-06,
      "loss": 0.0074,
      "step": 79500
    },
    {
      "epoch": 17.62502753910553,
      "grad_norm": 0.0027942194137722254,
      "learning_rate": 1.4891771315267681e-06,
      "loss": 0.0086,
      "step": 80000
    },
    {
      "epoch": 17.73518396122494,
      "grad_norm": 0.017785953357815742,
      "learning_rate": 1.420329367702137e-06,
      "loss": 0.0134,
      "step": 80500
    },
    {
      "epoch": 17.84534038334435,
      "grad_norm": 2.4632349014282227,
      "learning_rate": 1.3516192994051553e-06,
      "loss": 0.0118,
      "step": 81000
    },
    {
      "epoch": 17.95549680546376,
      "grad_norm": 0.009470663033425808,
      "learning_rate": 1.2827715355805244e-06,
      "loss": 0.0136,
      "step": 81500
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.6739226033421284,
      "eval_loss": 3.472620964050293,
      "eval_runtime": 51.4424,
      "eval_samples_per_second": 88.41,
      "eval_steps_per_second": 11.061,
      "step": 81702
    },
    {
      "epoch": 18.06565322758317,
      "grad_norm": 0.0020558612886816263,
      "learning_rate": 1.2139237717558933e-06,
      "loss": 0.0111,
      "step": 82000
    },
    {
      "epoch": 18.17580964970258,
      "grad_norm": 0.00018367076700087637,
      "learning_rate": 1.1450760079312623e-06,
      "loss": 0.0084,
      "step": 82500
    },
    {
      "epoch": 18.28596607182199,
      "grad_norm": 0.0005167803028598428,
      "learning_rate": 1.0762282441066314e-06,
      "loss": 0.0042,
      "step": 83000
    },
    {
      "epoch": 18.396122493941398,
      "grad_norm": 0.00042061757994815707,
      "learning_rate": 1.0073804802820004e-06,
      "loss": 0.0044,
      "step": 83500
    },
    {
      "epoch": 18.506278916060808,
      "grad_norm": 0.00022220592654775828,
      "learning_rate": 9.386704119850189e-07,
      "loss": 0.0112,
      "step": 84000
    },
    {
      "epoch": 18.616435338180217,
      "grad_norm": 0.0003270847664680332,
      "learning_rate": 8.698226481603878e-07,
      "loss": 0.0126,
      "step": 84500
    },
    {
      "epoch": 18.726591760299627,
      "grad_norm": 0.00028175502666272223,
      "learning_rate": 8.009748843357569e-07,
      "loss": 0.0074,
      "step": 85000
    },
    {
      "epoch": 18.836748182419036,
      "grad_norm": 0.00011951824853895232,
      "learning_rate": 7.321271205111258e-07,
      "loss": 0.0029,
      "step": 85500
    },
    {
      "epoch": 18.946904604538446,
      "grad_norm": 0.00025472414563409984,
      "learning_rate": 6.632793566864948e-07,
      "loss": 0.0051,
      "step": 86000
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.6759014951627089,
      "eval_loss": 3.525301456451416,
      "eval_runtime": 51.4679,
      "eval_samples_per_second": 88.366,
      "eval_steps_per_second": 11.055,
      "step": 86241
    },
    {
      "epoch": 19.057061026657856,
      "grad_norm": 0.0006832047365605831,
      "learning_rate": 5.945692883895132e-07,
      "loss": 0.0101,
      "step": 86500
    },
    {
      "epoch": 19.167217448777265,
      "grad_norm": 0.0002178904542233795,
      "learning_rate": 5.257215245648822e-07,
      "loss": 0.0075,
      "step": 87000
    },
    {
      "epoch": 19.277373870896675,
      "grad_norm": 0.0001402692578267306,
      "learning_rate": 4.568737607402512e-07,
      "loss": 0.0037,
      "step": 87500
    },
    {
      "epoch": 19.387530293016084,
      "grad_norm": 0.00019933069415856153,
      "learning_rate": 3.880259969156202e-07,
      "loss": 0.0079,
      "step": 88000
    },
    {
      "epoch": 19.497686715135494,
      "grad_norm": 0.007940555922687054,
      "learning_rate": 3.191782330909892e-07,
      "loss": 0.0025,
      "step": 88500
    },
    {
      "epoch": 19.607843137254903,
      "grad_norm": 0.0001361441391054541,
      "learning_rate": 2.5046816479400747e-07,
      "loss": 0.0138,
      "step": 89000
    },
    {
      "epoch": 19.717999559374313,
      "grad_norm": 0.00023193548258859664,
      "learning_rate": 1.8162040096937654e-07,
      "loss": 0.0072,
      "step": 89500
    },
    {
      "epoch": 19.828155981493722,
      "grad_norm": 0.0012137455632910132,
      "learning_rate": 1.1277263714474555e-07,
      "loss": 0.008,
      "step": 90000
    },
    {
      "epoch": 19.938312403613132,
      "grad_norm": 0.0001560118980705738,
      "learning_rate": 4.392487332011456e-08,
      "loss": 0.0098,
      "step": 90500
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.6763412489006156,
      "eval_loss": 3.5019032955169678,
      "eval_runtime": 51.5256,
      "eval_samples_per_second": 88.267,
      "eval_steps_per_second": 11.043,
      "step": 90780
    }
  ],
  "logging_steps": 500,
  "max_steps": 90780,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.91069301245952e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
