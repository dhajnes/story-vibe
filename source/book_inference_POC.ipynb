{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    AutoConfig\n",
    ")\n",
    "import os\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "# Download the Punkt tokenizer models\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"/home/andrej/Code/story-vibe/data/models/checkpoint-08_07_2024\"\n",
    "device = torch.device('cuda:0')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "model.to(device)\n",
    "config = AutoConfig.from_pretrained(MODEL_DIR)\n",
    "max_length = config.max_position_embeddings\n",
    "print(f\"Max length: {max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing a book into a format for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and segment the book\n",
    "BOOK_PATH = \"/home/andrej/Code/story-vibe/data/texts\"\n",
    "\n",
    "# SPLIT = \"paragraph\"  # \"sentence\"\n",
    "SPLIT = \"sentence\"\n",
    "with open(f'{BOOK_PATH}/alice_in_wonderland.txt', 'r') as file:\n",
    "    book_text = file.read()\n",
    "\n",
    "if SPLIT == \"paragraph\":\n",
    "    segments = book_text.split('\\n\\n')\n",
    "elif SPLIT == \"sentence\":\n",
    "    segments = nltk.sent_tokenize(book_text)\n",
    "\n",
    "def get_sentiment(text, argmax=False):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    # print(f\"Inputs: {inputs}\")\n",
    "    # print(f\"Inputs length: {len(inputs['input_ids'][0])}\")\n",
    "    if len(inputs['input_ids'][0]) > 350:\n",
    "        print(f\"Input length is larger than 350: {len(inputs['input_ids'][0])}\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    scores = outputs.logits.softmax(dim=-1).cpu().numpy()[0]\n",
    "\n",
    "    # return only the max sentiment\n",
    "    if argmax is True:\n",
    "        scores = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
    "    return scores\n",
    "\n",
    "T_START = time.time()\n",
    "sentiments = [get_sentiment(segment) for segment in segments]\n",
    "print(f\"Time taken for {SPLIT} split: {time.time() - T_START} [s].\")\n",
    "# Convert to numpy array for easy plotting\n",
    "sentiments = np.array(sentiments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do the same type of inference, but parallely - in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and segment the book\n",
    "BOOK_PATH = \"/home/andrej/Code/story-vibe/data/texts\"\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# SPLIT = \"paragraph\"  # \"sentence\"\n",
    "SPLIT = \"sentence\"  # \"sentence\"\n",
    "with open(f'{BOOK_PATH}/alice_in_wonderland.txt', 'r') as file:\n",
    "    book_text = file.read()\n",
    "\n",
    "if SPLIT == \"paragraph\":\n",
    "    segments = book_text.split('\\n\\n')\n",
    "elif SPLIT == \"sentence\":\n",
    "    segments = nltk.sent_tokenize(book_text)\n",
    "\n",
    "def get_sentiment(text, argmax=False):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    # print(f\"Inputs: {inputs}\")\n",
    "    # print(f\"Inputs length: {len(inputs['input_ids'][0])}\")\n",
    "    if len(inputs['input_ids'][0]) > 350:\n",
    "        print(f\"Input length is larger than 350: {len(inputs['input_ids'][0])}\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    scores = outputs.logits.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    # return only the max sentiment\n",
    "    if argmax is True:\n",
    "        scores = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
    "    return scores\n",
    "\n",
    "# Processing in batches\n",
    "T_START = time.time()\n",
    "all_sentiments = []\n",
    "\n",
    "print(\"segments: \", segments)\n",
    "for i in range(0, len(segments), BATCH_SIZE):\n",
    "    batch = segments[i:i + BATCH_SIZE]\n",
    "    sentiments = get_sentiment(batch)\n",
    "    all_sentiments.extend(sentiments)\n",
    "\n",
    "print(f\"Time taken for batched {SPLIT} split: {time.time() - T_START} [s].\")\n",
    "# Convert to numpy array for easy plotting\n",
    "all_sentiments = np.array(all_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model timing - CPU\n",
    "- Getting sentiments per sentence: 71.24 seconds.  \n",
    "  - with batchsize 16 - 63 seconds  \n",
    "  - with batchsize 8  - 55 seconds  \n",
    "  - with batchsize 4  - 50.5 seconds  \n",
    "  - with batchsize 2  - 54.7 seconds  \n",
    "- Getting sentiments per paragraph: 44.53 seconds.  \n",
    "  - with batchsize 8 - longer   \n",
    "  - with batchsize 4 - 42 seconds  \n",
    "  - with batchsize 2 - 41 seconds  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model timing - GPU\n",
    "- Getting sentiments per sentence: 9.43 seconds.  \n",
    "  - with batchsize 32 - 6.49 seconds  \n",
    "  - with batchsize 16 - 5.37 seconds  \n",
    "  - with batchsize 8  - 4.97 seconds  \n",
    "  - with batchsize 4  - 5.22 seconds  \n",
    "  - with batchsize 2  - 7.18 seconds  \n",
    "- Getting sentiments per paragraph: 6.00 seconds.  \n",
    "  - with batchsize 16 - 4.91 seconds \n",
    "  - with batchsize 8 - 4.32 seconds   \n",
    "  - with batchsize 4 - 4.00 seconds  \n",
    "  - with batchsize 2 - 4.61 seconds  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sentiments: {sentiments}\")\n",
    "print(f\"Shape of Sentiments: {sentiments.shape}\")\n",
    "print(f\"Labels: {model.config.id2label}\")\n",
    "\n",
    "minimal_labels = {\n",
    "                  \"negative\": [\"sadness\", \"fear\", \"anger\", \"disgust\"],\n",
    "                  \"neutral\": [\"neutral\", \"surprise\"],\n",
    "                  \"positive\": [\"happiness\"],\n",
    "                  }\n",
    "\n",
    "minimal_number_labels = {\n",
    "                        -1: [model.config.label2id[label] for label in minimal_labels[\"negative\"]],\n",
    "                         0: [model.config.label2id[label] for label in minimal_labels[\"neutral\"]],\n",
    "                        1: [model.config.label2id[label] for label in minimal_labels[\"positive\"]],\n",
    "                        }\n",
    "\n",
    "print(minimal_number_labels)\n",
    "maximal_number_labels = [0] * len(model.config.id2label)\n",
    "# for key, val in minimal_number_labels.items():\n",
    "#     for v in val:\n",
    "#         maximal_number_labels[v] = key\n",
    "\n",
    "for key, val in minimal_number_labels.items():\n",
    "    for v in val:\n",
    "        maximal_number_labels[v] = key\n",
    "\n",
    "print(f\"maximal_number_labels: {maximal_number_labels}\")\n",
    "\n",
    "# remapped_sentiment = [maximal_number_labels[sent] for sent in sentiments]\n",
    "# print(f\"Remapped sentiment: {remapped_sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 6 concurrent lines representing the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def validate_data(data):\n",
    "    \"\"\"\n",
    "    Ensure the data contains only finite numbers and handle NaNs.\n",
    "    \n",
    "    Parameters:\n",
    "    data (numpy array): The input data array.\n",
    "    \n",
    "    Returns:\n",
    "    numpy array: The validated data.\n",
    "    \"\"\"\n",
    "    # Replace NaN and inf values with zeros\n",
    "    data = np.nan_to_num(data)\n",
    "    return data\n",
    "\n",
    "# Apply Savitzky-Golay filter to smooth the running averages\n",
    "def smooth_data(data, window_size, polyorder=2):\n",
    "    \"\"\"\n",
    "    Smooth data using Savitzky-Golay filter.\n",
    "    \n",
    "    Parameters:\n",
    "    data (numpy array): The input data array.\n",
    "    window_size (int): The window size for the filter. It must be a positive odd integer.\n",
    "    polyorder (int): The order of the polynomial used to fit the samples. Default is 2.\n",
    "    \n",
    "    Returns:\n",
    "    numpy array: The smoothed data.\n",
    "\n",
    "    \"\"\"\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "    if window_size <= polyorder:\n",
    "        window_size = polyorder + 1\n",
    "        if window_size % 2 == 0:\n",
    "            window_size += 1\n",
    "\n",
    "    return savgol_filter(validate_data(data), window_size, polyorder)\n",
    "\n",
    "def running_average(data, window_size):\n",
    "    \"\"\"\n",
    "    Calculate the running average of a list with a specified window size.\n",
    "    \n",
    "    Parameters:\n",
    "    data (list or numpy array): The input data list.\n",
    "    window_size (int): The window size for calculating the running average.\n",
    "    \n",
    "    Returns:\n",
    "    numpy array: The running averages with NaN padding for incomplete windows.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    running_avg = np.full_like(data, np.nan, dtype=np.float64)\n",
    "    if len(data) >= window_size:\n",
    "        running_avg[window_size - 1:] = np.convolve(data, np.ones(window_size), 'valid') / window_size\n",
    "    return running_avg\n",
    "\n",
    "print(all_sentiments)\n",
    "\n",
    "window_size = 10\n",
    "running_avg_sentiments = np.array([running_average(all_sentiments[:, i], window_size) for i in range(all_sentiments.shape[1])]).T\n",
    "\n",
    "print(running_avg_sentiments)\n",
    "\n",
    "smoothed_sentiments = np.array([smooth_data(running_avg_sentiments[:, i], 11, 4) for i in range(running_avg_sentiments.shape[1])]).T\n",
    "\n",
    "# Plot sentiment timeline with running average\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, emotion in enumerate(['sadness', 'happiness', 'fear', 'anger', 'surprise', 'disgust', 'neutral']):\n",
    "    plt.plot(all_sentiments[:, i], label=emotion, lw=3)\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.legend()\n",
    "plt.title('Sentiment Timeline with Running Average')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot now the negative, neutral and positive curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (key, val) in enumerate(minimal_number_labels.items()):\n",
    "    print(f\"i: {i}, key: {key}, val:{val}\")\n",
    "\n",
    "supergroups = np.zeros([all_sentiments.shape[0], 3])\n",
    "\n",
    "for idx, val in enumerate(minimal_number_labels.values()):\n",
    "    supergroups[:, idx] = all_sentiments[:, val].sum(axis=1)\n",
    "\n",
    "\n",
    "window_size = 10\n",
    "running_avg_supergroups = np.array([running_average(supergroups[:, i], window_size) for i in range(supergroups.shape[1])]).T\n",
    "\n",
    "smoothed_supergroups = np.array([smooth_data(running_avg_supergroups[:, i], 11, 4) for i in range(running_avg_supergroups.shape[1])]).T\n",
    "smoothed_supergroups = smoothed_supergroups.clip(min=0, max=1)\n",
    "print(f\"Shape of smoothed supergroups: {smoothed_supergroups.shape}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "colors = [\"tab:red\", \"tab:purple\", \"tab:blue\"]\n",
    "for i, emotion in enumerate(['Negative', 'Neutral', 'Positive']):\n",
    "    plt.plot(smoothed_supergroups[:, i], label=emotion, color=colors[i], lw=3)\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.legend()\n",
    "plt.title('Reduced Sentiment score')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"smoothed_supergroups positive at 531: {smoothed_supergroups[531, :]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to show an overall score -i.e. one line\n",
    "# the sentiment probabilities are now used as weights for [-1, 0, 1]\n",
    "\n",
    "overall_scores = np.ones_like(smoothed_supergroups)\n",
    "overall_scores[:, 0] = -1\n",
    "overall_scores[:, 1] = 0\n",
    "overall_scores[:, 2] = 1\n",
    "print(overall_scores[:5, :])\n",
    "print(smoothed_supergroups[:5, :])\n",
    "overall_scores *= smoothed_supergroups\n",
    "\n",
    "print(overall_scores.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(overall_scores.sum(axis=1), label=\"Overall Sentiment\", color=\"tab:blue\", lw=3)\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Reduced Sentiment Score')\n",
    "plt.legend()\n",
    "plt.title('Reduced Sentiment score')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.ylim(-1,1)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "story-vibe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
