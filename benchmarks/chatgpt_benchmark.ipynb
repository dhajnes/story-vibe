{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Different ChatGPTs, to see whether the SOTA chatbots perform well on 0-shot and few-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# read API key from local machine\n",
    "with open(\"/home/andrej/Documents/open_ai/made-with-ml-key.txt\", \"r\") as file:\n",
    "    api_key = file.read()\n",
    "    api_key = re.sub(r'\\s+', '', api_key)\n",
    "\n",
    "import openai\n",
    "openai.api_key = api_key\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sentiment training dataset from reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# pandas also relies on numpy for random sampling\n",
    "np.random.seed(42)  # the answer to everything\n",
    "\n",
    "dataset = load_dataset(\"google-research-datasets/go_emotions\", \"simplified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_labeled(df):\n",
    "    single_labels = df['labels'].apply(lambda x: x if len(x) <= 1 else None)\n",
    "    single_labels = single_labels.dropna()  #  leave out the multilabeled ones\n",
    "\n",
    "    # extract the singlelabeled data by index via iloc\n",
    "    single_df = df.iloc[single_labels.index]  \n",
    "\n",
    "    # transform the singlelabeled data labels from list (e.g. [8]) into int (e.g. 8)\n",
    "    single_df['labels'] = single_df['labels'].apply(lambda x: x[0])\n",
    "\n",
    "    return single_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12667/449914299.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_df['labels'] = single_df['labels'].apply(lambda x: x[0])\n",
      "/tmp/ipykernel_12667/449914299.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_df['labels'] = single_df['labels'].apply(lambda x: x[0])\n"
     ]
    }
   ],
   "source": [
    "labels = dataset['train'].features['labels'].feature.names\n",
    "\n",
    "# labels are by default in a list, filter them and reassign them to an integer instead\n",
    "long_train_df = pd.DataFrame(dataset['train'])\n",
    "train_df = get_single_labeled(long_train_df)\n",
    "\n",
    "long_test_df = pd.DataFrame(dataset['test'])\n",
    "test_df = get_single_labeled(long_test_df)\n",
    "before_adding = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4595 entries, 0 to 4594\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    4595 non-null   object\n",
      " 1   labels  4595 non-null   int64 \n",
      " 2   id      4595 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 107.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df.info()\n",
    "test_df.info()\n",
    "\n",
    "# adding a few more made up grief comments to the testing dataset, there are only 2 examples labeled grief...\n",
    "grief_additionals = [\n",
    "    \"I still can\\'t bring myself to sit in his chair. Every time I walk past it, I just feel this overwhelming emptiness.\",\n",
    "    \"Every time I walk through the house, I get hit with memories that make me cry all over again. It\\'s like a never-ending cycle.\",\n",
    "    \"I keep reaching for my phone to text him, then remember he\\'s gone. It\\'s like a punch in the gut every single time.\",\n",
    "    \"The holidays used to be my favorite time of year, but now they\\'re just painful reminders of the family we\\'ve lost.\",\n",
    "    \"Sometimes I find myself holding onto his old jacket because it still smells like him. It\\'s comforting and heartbreaking all at once.\"\n",
    "    ]\n",
    "\n",
    "new_entries = {\"text\": [],\n",
    "               \"labels\": [],\n",
    "               \"id\": []\n",
    "               }\n",
    "\n",
    "for id, text in enumerate(grief_additionals):\n",
    "    new_entries[\"text\"].append(text)\n",
    "    new_entries[\"labels\"].append(16)  # the id for \"grief\" label\n",
    "    new_entries[\"id\"].append(f\"manual_id_{id}\")\n",
    "\n",
    "if before_adding:\n",
    "    new_entries_df = pd.DataFrame(new_entries)\n",
    "    test_df = pd.concat([test_df, new_entries_df], ignore_index=True)\n",
    "    before_adding = False\n",
    "    \n",
    "test_df.query('labels == 16').shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dict(df, n_samples_per_category=1):\n",
    "    test_dict = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        # print(f\"Sampling label: {label} with label id: {i}\")\n",
    "        # print(f\"There is \", df.query(f'labels == {i}').shape[0], f\" of {label} in the Test set.\")\n",
    "        sample = df.query(f'labels == {i}').sample(n_samples_per_category)\n",
    "        test_dict[label] = list(sample['text'])\n",
    "    return test_dict\n",
    "\n",
    "\n",
    "def sample_few_shot(df):\n",
    "    \"\"\"Samples one random item for each label from a given DataFrame.\"\"\"\n",
    "    few_shot_dict = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        sample = df.query(f'labels == {i}').sample(1)\n",
    "        while \"[NAME]\" in sample.text.item():\n",
    "            sample = df.query(f'labels == {i}').sample(1)\n",
    "\n",
    "        few_shot_dict[label] = sample.text.item()\n",
    "    return few_shot_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot training data:\n",
      "{'admiration': \"Seattle's train is nice... once you get there. It is an absolute hike from the terminal\", 'amusement': 'Haha, only one species. More the Cockatoos', 'anger': 'Oh go fuck yourself with your BS generalization.', 'annoyance': 'Pretty sure itâ€™s going on in the apartment across from me right now. My neighbors are trashy', 'approval': 'I think we can all agree that this is the right answer.', 'caring': 'Most likely itâ€™s not a tumour since cancerous tumours arenâ€™t usually painful. You still should go check it out ASAP.', 'confusion': 'Iâ€™m not sure what there is to disagree about. It was obviously a subjective claim.', 'curiosity': 'Canâ€™t wait to see my IG page blow up with it smh', 'desire': 'I wish yall would stay off the fucking roads when youre drinking beer. Mind you, on a bike I may just get that wish after your first night out.', 'disappointment': 'I also posted about this a few days ago. Maybe they have different designers but none of them has follow-up or approval from a single person, unfortunate', 'disapproval': 'Polyamorous ainâ€™t a sexual orientation hon', 'disgust': 'Reddit culture is truly the worst.', 'embarrassment': 'It makes for awkward conversation when I ask \"What\\'s your favorite song?\" And I get \"I just liked the shirt\" in response', 'excitement': 'My aim in battlefornt 2 is pretty good = navy seal, elite unit', 'fear': 'Thatâ€™s not munchausen. She has a diagnosed illness thatâ€™s a terrible, terrible one to suffer from. This is a pretty shitty reply.', 'gratitude': 'Thank you, you are blessed', 'grief': \"I'm glad you're doing a bit better. Sorry about your grandma. Good luck.\", 'joy': \"I got a weird vibe when he was placed on Colliton's staff, so I'm really glad it's turned out the way it did. \", 'love': 'I love how heâ€™s still smiling while being eaten', 'nervousness': 'Everytime I see something in this sub that looks sharp, I get very worried. ', 'optimism': 'Keep working at it with your partner. I hope it all works out for you.', 'pride': \"I'm proud that this is the first response I see.\", 'realization': 'After 6 weeks, anything becomes a habit I hear. ', 'relief': 'Whew. I thought no one else would recognize Mac Tonight.', 'remorse': 'Sorry for your loss. Thoughts and prayers.', 'sadness': 'Iâ€™m crying omfg', 'surprise': 'Shockingly, some people continue to educate and improve themselves. You might benefit from it.', 'neutral': \"I'm betting she's 18 or 19 and freaking out about bills. She'll recognize her error years from now and regret it for a long time.\"}\n",
      "Sampled benchmark dataset:\n",
      "{'admiration': ['Best doggo ever', \"I do have few friends from there and it's a lovely nation too.\", 'Fantastic pub, went there last year as part of the liquid history pub tours. ', 'I believe he means he was a very pretty child to become otherwise after puberty...', 'GO SUB TO HIM HES THE BEST', '[NAME] so cool', 'Good idea, brought to the table by a questionable at best minister, likely for the purpose of shifting focus away from his failures. '], 'amusement': [\"Oh? There's financial trouble in heaven? Lol\", 'Lol I always go with public speaking (\"but I\\'m trying to be better at it!!\"). ', 'Lmao, this guy is a tool.', \"Free weed lol don't get what you're complaining about.\", \"Exactly, but I guess I've gotten used to people forgetting the club exists haha\", 'Ahh, so the exact same place he was last time. wonderful lol', 'i did, but it was at 3 am before i went to bed, so iâ€™m gonna cheat and count it as 2018 LOL.'], 'anger': ['I would play the fuck out of this game', \"You should've smashed his head into it.\", 'I think the biggest fucking thing is that apparently reaper has a goddamn family himself.', \"> punishment for saying no to rape Surely if you wanted to rape someone you'd have to punish them for saying yes...\", 'Good for you for shutting that door! You are not responsible for him. Heâ€™s a grown ass man who made his own mistakes.', '[NAME] I hate my hometown', 'The attraction and the action are two separate things, and you know that. No one chooses who they are attracted to. Stop it. '], 'annoyance': [\"If you can't see how the mass killing of Landlords is related to Communist ideology, there is really no point discussing further.\", 'No itâ€™s definitely you. Time for you to grow up.', \"It's actually somewhat maddening to me that there are people who watch his video and actually think he is doing a public service. Yikes..\", 'And itâ€™s always so uncomfortably awkward when someone says shit like this to you.', \"100%. Please ignore him. He's annoying af and survives off attention\", 'Canâ€™t stand that dwarfism [NAME] she is so cringe', '*DRAINS, CLOGS, BACKED UP LOGS [NAME]!* *OH, NO, TOILET OVERFLOW [NAME]!*'], 'approval': [\"As a whole, yes, if it wasn't for Classified being the greatest thing to come to zombies since bo1, then I'd have to agree.\", 'No I am still friends with the person I value his friendship he can just be...judgy?', 'it is actually called a mechanical bull', \"Yeah that dragon one with the same style ? Mesmerizing. I believe there's also one close to Civic center\", 'I understand that but I enjoy the silence and lonely feeling I have.', 'Feel free to leave.', 'Bad sarcasm in response to a bad joke seems about right to be fair.'], 'caring': ['learn to say no more. After a few times you have something you like destroyed it gets easier.', 'She sounds like she could be depressed. People who have depression need care, love and help to get better, not internet shaming. ', 'Happy Birthday [NAME]. You wont read this message but itll be here.', 'If [NAME] is being considered for all defense, [NAME] needs more love too', 'Hope all is well now xo', 'On days like this you can get an extra scoop. Just to make sure you have the finnnnnessst meals ;)', \"This is something that has to be learned from experience. Don't be hard on yourself!\"], 'confusion': ['I donâ€™t know what Iâ€™m to say Iâ€™ll say it anyway', 'why is this hard to believe itâ€™s totally believable', 'Maybe Iâ€™m unsure of that', 'are your feelings hurt?', \"Why am I seeing this everywhere now? This wasn't in my vocabulary last week.\", 'Generally you are still a â€œteacherâ€ but Iâ€™m not sure 100%. I know my instructional coach role is still â€œteacherâ€ contract/pay.', 'Canâ€™t even tell whatâ€™s happening here. This isnâ€™t cringe.'], 'curiosity': [\"I'M MR. [NAME]! HOW DID WE GET ROPED INTO THIS?\", \"Unlikely, but who knows? Memory speed rarely makes a difference in gaming, but I've seen stranger things. \", 'Did you noticed they removed my post? Yep.', 'not writing some stats today [NAME]? just curious xD', 'Have you guys played Vancouver recently or has [NAME] found someone else to cut his hair?', 'iS thIs a MeTapHor FoR LifE?', \"Can you please update me! I'm in the exact position! 24FHL with 21MLL\"], 'desire': ['Good for you! I wish I had run for my life at 18, but brainwashing is real', \"They'd never give her a crown but it would be so good to see her back on my screen.\", \"Don't see a W tonight. We need a miracle.\", 'Translation }}} I wish I could afford it.', 'I want Cowboys and Bears to win so the Raiders draft picks are at best picks 25 & 26', \"I'd love to collab with some reddit folks on NFL Draft prospect scouting, rankings and mock drafts if anyone is interested.\", 'That whole thread makes me want to shake babies.'], 'disappointment': ['Your TLDR sucks', 'That number seems a bit low to me', 'making us look like punks, disappointing', 'Lovely places to buy from but very hard to get a good price as a seller because of their high rents (and bargaining expertise!)', 'It is. Itâ€™s so bad. Then I start blaming myself for liking them. Itâ€™s like I have no control over this.', 'Crap. I need more Excedrin. STAT.', 'That\\'s a lot of words to say \"I\\'m upset that women don\\'t want to date me.\"'], 'disapproval': ['I feel like its got to do with the bad desync in the game right now.', \"Nah man I prefer endless cause of the part where he goes WOMWOMWOMWOMWOMWOM WOOOOOO REEEEEEEEE like that's lyrical genius right there\", '[NAME] gets a lot of unfair criticism. [NAME], too', 'Trier is low key an awful defender', 'Yep...this sub blasted me for hating the casey hire and still refuses to admit his big faults', \"In looking at the questions answered in the AMAs following the [NAME] podcast, I don't see any related to [NAME] or race/IQ. \", \"Not really, just wanted to know why specifically you thought he was on gear. (Because I honestly don't see it)\"], 'disgust': ['cause he constantly hates on [NAME] for no reason other than Petry having the puck on his stick more than anyone else on the team', \"Weird as I do know I've seen CoC waste/recycling services trucks picking up bins as early as 6:30AM.\", 'That\\'s weird to hear since in Hebrew \"Son of man\"- Ben Adam, simply refers to humans in general.', 'A horrendous amount of Sesame oil, god, that would be awful.', \"Yeah he's a cunt but that doesn't mean he should be prosecuted for a joke. No matter how bad taste it was.\", 'People are disgusting and insane.', \"It's going to get awfully dark and cold at night.\"], 'embarrassment': ['I never knew cringing could be so ...cathartic.', 'The questions are normal enough, but all at once and leading with them is a little weird.', \"And yet it looks like one thing you can't is read. Shame shame.\", 'Yes, we are going to kink shame you. ', \"Yeah, I always thought [NAME] would be an improved [NAME]. It's a damn shame we haven't thrown to him more often.\", \"That's a maryland fan comment. You should be ashamed of yourself.\", 'As a society we should be ashamed of the fact that this is even a question. Let the suffering stop obviously.'], 'excitement': [\"[NAME] is amped, I'm excited that he's excited\", 'I didnt know that sub existed,im faaaaaar too excited, thats my next hour of skivving work sorted!! ', \"Yikes. I was kind of excited to get a new [NAME] if he gets last man in but I'll pass on these butt ugly jerseys.\", \"I'm more interested in why there are goldfish in the picture...\", \"This. We already have so much more OL talent. We need another WR and TE, but I'm kinda excited\", 'I am inexplicably excited by [NAME]. I get so excited by how he curls passes', 'Take a seat young ragewalker.'], 'fear': [\"Deathly afraid, the undersides of boats too. I can't look if I see them in a picture or movie\", \"Is this a real thing? I'm a terrible stoner.\", \"I honestly predict a riot on the scale of the 2011 ones if we undergo a no-deal brexit - possibly even worse. It's terrifying.\", 'The thought of shooting anything at asylum seekers is appalling.', \"Help me [NAME] I'm bully in high school for no reason.\", 'It was done before and it was terrible', 'I want to go scuba diving so bad, but swimming in anything bigger than a pool terrifies me.'], 'gratitude': ['This was extremely helpful, many thanks!', 'Thank you, manðŸŒ±', 'Thanks. I guess.', 'Thank you very much I appreciate the enthusiasm btw do you know more or less how much space will I need to install it?', 'Thank you, next! ', 'Great idea! Thanks :)', \"I'll have one in front and one behind. Please and thank you!\"], 'grief': [\"The holidays used to be my favorite time of year, but now they're just painful reminders of the family we've lost.\", '[NAME] death is just so..... senseless. Why? WHY??? The based gods have forsaken us', \"Sometimes I find myself holding onto his old jacket because it still smells like him. It's comforting and heartbreaking all at once.\", 'Rip the guy from psych', \"I still can't bring myself to sit in his chair. Every time I walk past it, I just feel this overwhelming emptiness.\", \"I keep reaching for my phone to text him, then remember he's gone. It's like a punch in the gut every single time.\", \"Every time I walk through the house, I get hit with memories that make me cry all over again. It's like a never-ending cycle.\"], 'joy': ['My fiancÃ© and I went to a friends house and just hung out until midnight and watched fireworks, it was so chill and perfect!', 'Cool! Glad to see some cooperation.', 'Well [NAME] made me laugh', \"That's that frequency dying in your ears. Enjoy it, because you will never hear that exact frequency again\", 'Very cool toys, very cool video, very cool hostd', 'ðŸ˜‚ i need one too iâ€™m on break and honestly my life revolves around reddit at this point, cake day is special enjoy it! ', 'Had one good year that was it, then joins a god squad that struggles to qualify'], 'love': ['So more [NAME]? No thanks. Love the guys, but thatâ€™s for side projects. ', 'People on Reddit barely know anything about law but they love to get riled up about the little that they do know', \"[NAME] dumb friends wanted him with the little baddie. and now he's gonna end up back in jail. Oh [NAME] I love [NAME].\", 'Loving everyone so far. This is going to be a great season.', 'I like Shred 415', \"Used to love Thai-tanic. Haven't been in ages.\", 'I love this. you get a favorite.'], 'nervousness': ['I know, I know, but CAN YOU BLAME ME FOR BEING NERVOUS', 'I feel a sense of unease tbh', 'Iâ€™m just worried about his attitude and approach with younger players. Edit-re worded', \"No response after a week? That's something to worry about.\", \"Oh, it's definitely working and that worries me a lot. \", 'I donâ€™t understand how her parents were able to take kid when she claims they are horrible alcoholics', \"Really worried about NISA translating it, but at this point I don't care any more, as long as we get an english version of it.\"], 'optimism': ['Now you have to make up all these downvotes with some low-hanging-fruit criticism comment of [NAME] or [NAME]. Good luck and cheers!', 'All I can say is.. good luck bro', 'I plan on being respectful lol. I hope heâ€™s there.', \"I want to change though. If I'm around those people I will remain the same way. Right?\", 'Shaving her legs, hoping the video didnâ€™t cut short and thatâ€™s all she shaved in there....', 'I would try rubbing alcohol, high percentage. Looks greasy to me.', 'I hope so but doubt it...'], 'pride': ['My jersey has the great number 10 on it!!', 'I am proud to be racist No one in real life will know this', 'I have no shame in saying I still have my blanket from when I was a child. And a favorite [NAME] plushie.', 'Yep. I did this in uni, got mad respect for holding my \"booze\". ', \"That's nothing, before BSE we did horrible things with bone meal animal feed. Cannibal cows.\", \"I only eat cronuts cuz I'm sophisticated!\", 'Boy what an accomplishment, so proud!'], 'realization': ['#RejectingIslam because it is the *ideas* [RELIGION] promotes that turned me away from it.', 'Oh, I realized that moments after rolling down my window, when his hand came through the space. ', \"I haven't seen a single [NAME] article. But there have been a few [NAME] articles around recently.\", 'This was not only true, but pleasing to watch.', 'Well if we just started in the second quarter in both games...we would have come out ahead!', \"nah it takes it a lot more than one time, I reckon you'll be fine considering your aware of the risk\", \"I've realized after more than 100 hours that you can dismount a horse without jumping off\"], 'relief': ['This is really helpful to point out!!', \"I'm glad it only sprayed soda when his thumb went into the can, and not blood everywhere.\", 'Resetting a dislocated knee hurts like hell but it feels a lot better immediately after.', 'I have little to no anxiety and it really helps me when i have to take a test.', 'Iâ€™ve exposed on social media. It made me feel better so I donâ€™t care what anyway has to say about it.', 'at least it wasnâ€™t the evil [NAME].', 'Praise the [NAME] for REALITY! WOOF!!!!!'], 'remorse': [\"Ugh I'm sorry man! Jerk off until your heart is content and don't apologize for it!\", '[NAME]. Im sorry', \"I apologize, that sincerely was meant for Askreddit. If you look at my history you'll see that's where I always post. My mistake.\", \"Okay, I'll try to find one. Sorry about that.\", 'I have a bad feeling Iâ€™m gonna regret not tuning into this', 'You still didnâ€™t answer the question. Sorry itâ€™s bugging me :)', 'Guilty as well!'], 'sadness': ['THIS IS TRAUMATISING', 'If thatâ€™s true itâ€™s very desperate. You would think he had some better way of communicating.', 'Im so sad how that movie turned out. We could have achived something good', 'I feel sorry for people that think Reddit (or even some random sub-reddit) is \"an international stage\".', \"It's sad how long it took me to get that. Haha got em\", 'Sad thing is it would probably forcibly ground the plane.', \"Can't relate because the sadness and loneliness is constant ðŸ˜Ž\"], 'surprise': ['Oh for sure. Sometimes I wonder if they are actually harming there cause with the over the top hypocrisy the newcomers seem to see it quite quickly.', 'Wack. Oh heard some 17 year olds are doing it too.', 'Unexpected Hail corporate.', 'As a Florida girl I have no clue how you all have not died. I could never live there.', 'The miracle was just that. Because we all know the Vikings would fail the next game.', \"Refreshmentos! What's that? It's new!\", \"That's a surprise from this guy.\"], 'neutral': ['Same old b.s.', 'Follow up #2: Story has been removed', 'So youâ€™re telling me [NAME] hasnâ€™t got a baby face?', 'Not enough accurate data on [NAME] civil to stay true to their identity unless they want to make a Spanish invasion related storyline', 'In what ways has [NAME] out-coached [NAME]? I see this all the time and yet never any examples.', 'Tell me a couple', 'Just dump it on the other side of that fence down there...ssss']}\n"
     ]
    }
   ],
   "source": [
    "few_shot_train = sample_few_shot(train_df)\n",
    "test_dict = create_test_dict(test_df, 7)\n",
    "print(f\"Few-shot training data:\\n{few_shot_train}\")\n",
    "print(f\"Sampled benchmark dataset:\\n{test_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the OpenAI API GPT setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tag(model, system_content=\"\", assistant_content=\"\", user_content=\"\"):\n",
    "    try:\n",
    "        # Get response from OpenAI\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"assistant\", \"content\": assistant_content},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "        )\n",
    "        # predicted_tag = response.to_dict()[\"choices\"][0].to_dict()[\"message\"][\"content\"]\n",
    "        predicted_tag = response.choices[0].message.content\n",
    "        return predicted_tag\n",
    "\n",
    "    except (openai.error.ServiceUnavailableError, openai.error.APIError) as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot testing of various GPT models by OpenAI for benchmarking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT 3.5-turbo\n",
    "> NOTE: This model will soon be deprecated by OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The system content is:\n",
      "\n",
      "You are an NLP sentiment prediction tool. Your goal is to predict a label given an input sequence by the user.\n",
      "You must choose between one of the following labels for each input: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'].\n",
      "Only respond with the label name and nothing else.\n",
      "admiration\n"
     ]
    }
   ],
   "source": [
    "# Get tag\n",
    "model = \"gpt-3.5-turbo\"\n",
    "system_content = f\"\"\"\n",
    "You are an NLP sentiment prediction tool. Your goal is to predict a label given an input sequence by the user.\n",
    "You must choose between one of the following labels for each input: {labels}.\n",
    "Only respond with the label name and nothing else.\"\"\"\n",
    "print(f\"The system content is:\\n{system_content}\")\n",
    "\n",
    "assistant_content = \"\"\n",
    "user_content = test_dict['admiration'][0]\n",
    "# print(f\"User content: {user_content}\")\n",
    "tag = get_tag(model=model, system_content=system_content, assistant_content=assistant_content, user_content=user_content)\n",
    "print(tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "story-vibe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
